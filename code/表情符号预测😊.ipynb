{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Âü∫‰∫éÊñáÊú¨ÁöÑË°®ÊÉÖÁ¨¶Âè∑È¢ÑÊµãÊ®°Âûãüòäüòäüòä\n",
    "### Êï∞ÊçÆÊîØÊåÅÔºögolve.6B.300d.txt  (‰∏ãËΩΩÈìæÊé•https://nlp.stanford.edu/projects/glove/Ôºâ\n",
    "### ËÆ≠ÁªÉÈõÜÊñá‰ª∂Ôºötrain_emoji.csv ÊµãËØïÈõÜÊñá‰ª∂Ôºötest_emoji.csv\n",
    "### Ê®°Âûã‰ΩøÁî®ÔºöLSTMÁ•ûÁªèÁΩëÁªú GRUÁ•ûÁªèÁΩëÁªú\n",
    "### È°πÁõÆÊó∂Èó¥Ôºö2020Âπ¥4Êúà25Êó•"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 ÂØºÂÖ•emojiÂ∫ì(‰∏ãËΩΩÂèäÂÆâË£Öpip3 install emoji)+ÈÉ®ÂàÜemojiÂèØËßÜÂåñ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üß°\n",
      "‚öæ\n",
      "üòÉ\n",
      "üòì\n",
      "üç¥\n"
     ]
    }
   ],
   "source": [
    "import emoji\n",
    "\n",
    "# ÂÆö‰πâË°®ÊÉÖËØçÂÖ∏Â∫ì\n",
    "emoji_dic = {0:':orange_heart:',1:':baseball:',2:':grinning_face_with_big_eyes:', \n",
    "             3:':downcast_face_with_sweat:',4:':fork_and_knife:'}\n",
    "\n",
    "# ÈÄöËøáemojiÂ∫ìËæìÂá∫Ë°®ÊÉÖÁ¨¶Âè∑\n",
    "for tmp in emoji_dic.values():\n",
    "    print(emoji.emojize(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 ËΩΩÂÖ•ËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÔºåÂØπÊï∞ÊçÆËøõË°åÈ¢ÑÂ§ÑÁêÜ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ËΩΩÂÖ•Êï∞ÊçÆÂÆåÊØïÔºåËÆ≠ÁªÉÈõÜÊï∞ÊçÆÈïøÂ∫¶:132,ÊµãËØïÈõÜÊï∞ÊçÆÈïøÂ∫¶:56\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "train_data = pd.read_csv('train_emoji.csv', header=None)\n",
    "test_data = pd.read_csv('test_emoji.csv', header=None)\n",
    "print('ËΩΩÂÖ•Êï∞ÊçÆÂÆåÊØïÔºåËÆ≠ÁªÉÈõÜÊï∞ÊçÆÈïøÂ∫¶:{},ÊµãËØïÈõÜÊï∞ÊçÆÈïøÂ∫¶:{}'.format(train_data.shape[0], test_data.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòì\n",
      "I am proud of your achievements üòÉ\n",
      "It is the worst day in my life üòì\n",
      "Miss you so much üß°\n",
      "food is life üç¥\n",
      "I love you mum üß°\n",
      "Stop saying bullshit üòì\n",
      "congratulations on your acceptance üòÉ\n",
      "The assignment is too long  üòì\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "# Â∞ÜËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÊï∞ÊçÆÊåâÁÖßÁâπÂæÅÂíåÊ†áÁ≠æËøõË°åÂàíÂàÜ\n",
    "train_X = train_data[0]\n",
    "train_y = train_data[1]\n",
    "test_X = test_data[0]\n",
    "test_y = test_data[1]\n",
    "\n",
    "# ‰ª•ÊµãËØïÈõÜ‰∏∫‰æãÊäΩÂèñÂâç10‰∏™Ê†∑Êú¨ËøõË°åprint\n",
    "for i in range(10):\n",
    "    print(train_X[i], emoji.emojize(emoji_dic[train_y[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Âä†ËΩΩËØçÂêëÈáèÂÆåÊØïÔºåËØçÂêëÈáèÂ∫ìÈïøÂ∫¶‰∏∫:400000\n"
     ]
    }
   ],
   "source": [
    "# Âä†ËΩΩËÆ≠ÁªÉÂ•ΩÁöÑËØçÂêëÈáèÊñá‰ª∂glove.6B.50d\n",
    "word_embed = dict()\n",
    "for line in open('/Users/xujie/Desktop/Python/nlp/data/word_embeding/glove.6B.300d.txt'):\n",
    "    line = line.split()\n",
    "    word = line[0]\n",
    "    embed_vec = line[1:]\n",
    "    word_embed[word] = list(map(float, embed_vec))\n",
    "print('Âä†ËΩΩËØçÂêëÈáèÂÆåÊØïÔºåËØçÂêëÈáèÂ∫ìÈïøÂ∫¶‰∏∫:{}'.format(len(word_embed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Â∞ÜËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÁöÑtrain_XÂíåtest_XËΩ¨Âåñ‰∏∫ËØçÂêëÈáèÂΩ¢Âºè\n",
    "dim_embed = 300 # ÂÆö‰πâËØçÂêëÈáèÁª¥Â∫¶\n",
    "max_sent_len = 10 # ÂÆö‰πâÊúÄÂ§ßÂçïËØçÈïøÂ∫¶\n",
    "\n",
    "# ÂÆö‰πâËΩ¨ÂåñÂáΩÊï∞convert2embed()\n",
    "def convert2embed(obj_data):\n",
    "    out_embed = np.zeros((obj_data.shape[0], max_sent_len, dim_embed))\n",
    "    for i, line in enumerate(obj_data):\n",
    "        line = line.split()\n",
    "        for j, word in enumerate(line):\n",
    "            if word.lower() not in word_embed.keys(): continue\n",
    "            out_embed[i][j] = word_embed[word.lower()]\n",
    "    return out_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ÁªìÊûÑÂåñËÆ≠ÁªÉÈõÜÂíåÊµãËØïÈõÜÊï∞ÊçÆ(Â∞ÜÁâπÂæÅXËΩ¨Âåñ‰∏∫ËØçÂêëÈáèÔºåÂ∞ÜÊ†áÁ≠æyËΩ¨Âåñ‰∏∫one-hotÁºñÁ†Å)\n",
    "import tensorflow as tf\n",
    "train_embed = tf.constant(convert2embed(train_X))\n",
    "test_embed = tf.constant(convert2embed(test_X))\n",
    "train_y_one_hot = tf.one_hot(train_y, depth=5)\n",
    "test_y_one_hot = tf.one_hot(test_y, depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 Êê≠Âª∫Ê∑±Â∫¶Á•ûÁªèÁΩëÁªúÊ°ÜÊû∂"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers, Sequential, optimizers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_2 (LSTM)                (None, 10, 64)            93440     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 64)                33024     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 126,789\n",
      "Trainable params: 126,789\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ÂÆû‰æãÂåñLSTMÊ∑±Â∫¶ÁΩëÁªú\n",
    "model_LSTM = Sequential()\n",
    "# Âä†ÂÖ•Á¨¨‰∏Ä‰∏™LSTMÂ±Ç ËæìÂÖ•Áª¥Â∫¶max_sent_len * dim_embed\n",
    "model_LSTM.add(layers.LSTM(64, input_shape=(max_sent_len,dim_embed), return_sequences=True))\n",
    "# ÈöèÊú∫Â§±Ê¥ªÈò≤Ê≠¢ËøáÊãüÂêà ÂèÇÊï∞=0.4\n",
    "model_LSTM.add(layers.Dropout(0.4))\n",
    "# Âä†ÂÖ•Á¨¨‰∫å‰∏™LSTMÂ±Ç\n",
    "model_LSTM.add(layers.LSTM(64, return_sequences=False))\n",
    "# ÈöèÊú∫Â§±Ê¥ªÈò≤Ê≠¢ËøáÊãüÂêà ÂèÇÊï∞=0.3\n",
    "model_LSTM.add(layers.Dropout(0.4))\n",
    "# ÊúÄÂêéÂä†ÂÖ•ÂÖ®ËøûÊé•Â±ÇÔºåÁî®softmaxÊøÄÊ¥ªÂáΩÊï∞ËæìÂá∫\n",
    "model_LSTM.add(layers.Dense(5, activation='softmax'))\n",
    "# ÁºñËØëÊ®°Âûã: ‰ºòÂåñÂô® Adam; ÊçüÂ§±ÂáΩÊï∞ ‰∫§ÂèâÁÜµÊçüÂ§±; ‰ºòÂåñÂáÜÂàô Á≤æÁ°ÆÂ∫¶\n",
    "model_LSTM.compile(optimizer=optimizers.Adam(lr=0.01), \n",
    "              loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# ËæìÂá∫ÁΩëÁªúÁªìÊûÑ\n",
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_2 (GRU)                  (None, 10, 64)            70272     \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 10, 64)            0         \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 64)                24960     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 325       \n",
      "=================================================================\n",
      "Total params: 95,557\n",
      "Trainable params: 95,557\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# ÂÆû‰æãÂåñGRUÊ∑±Â∫¶ÁΩëÁªú\n",
    "model_GRU = Sequential()\n",
    "# Âä†ÂÖ•Á¨¨‰∏Ä‰∏™GRUÂ±Ç ËæìÂÖ•Áª¥Â∫¶max_sent_len * dim_embed\n",
    "model_GRU.add(layers.GRU(64, input_shape=(max_sent_len,dim_embed), return_sequences=True))\n",
    "# ÈöèÊú∫Â§±Ê¥ªÈò≤Ê≠¢ËøáÊãüÂêà ÂèÇÊï∞=0.4\n",
    "model_GRU.add(layers.Dropout(0.4))\n",
    "# Âä†ÂÖ•Á¨¨‰∫å‰∏™GRUÂ±Ç\n",
    "model_GRU.add(layers.GRU(64, return_sequences=False))\n",
    "# ÈöèÊú∫Â§±Ê¥ªÈò≤Ê≠¢ËøáÊãüÂêà ÂèÇÊï∞=0.3\n",
    "model_GRU.add(layers.Dropout(0.4))\n",
    "# ÊúÄÂêéÂä†ÂÖ•ÂÖ®ËøûÊé•Â±ÇÔºåÁî®softmaxÊøÄÊ¥ªÂáΩÊï∞ËæìÂá∫\n",
    "model_GRU.add(layers.Dense(5, activation='softmax'))\n",
    "# ÁºñËØëÊ®°Âûã: ‰ºòÂåñÂô® Adam; ÊçüÂ§±ÂáΩÊï∞ ‰∫§ÂèâÁÜµÊçüÂ§±; ‰ºòÂåñÂáÜÂàô Á≤æÁ°ÆÂ∫¶\n",
    "model_GRU.compile(optimizer=optimizers.Adam(lr=0.01), \n",
    "              loss=losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "# ËæìÂá∫ÁΩëÁªúÁªìÊûÑ\n",
    "model_GRU.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 Ê®°ÂûãÈ¢ÑÊµã‰∏éËØÑ‰º∞ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "\n",
    "# ËÆ≠ÁªÉLSTMÊ∑±Â∫¶Á•ûÁªèÁΩëÁªú\n",
    "epochs = 60 # ÂÆö‰πâËø≠‰ª£Ê¨°Êï∞\n",
    "checkpoint_LSTM = ModelCheckpoint('best_model_LSTM.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
    "checkpoint_GRU = ModelCheckpoint('best_model_GRU.h5', monitor='val_loss', verbose=True, save_best_only=True)\n",
    "# ÊèêÂâçÁªàÊ≠¢ÔºåÈò≤Ê≠¢ËøáÊãüÂêà\n",
    "early_stop = EarlyStopping(monitor='val_accuracy', patience=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/60\n",
      " 64/105 [=================>............] - ETA: 5s - loss: 1.6112 - accuracy: 0.1250\n",
      "Epoch 00001: val_loss improved from inf to 1.60994, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 11s 104ms/sample - loss: 1.5922 - accuracy: 0.2381 - val_loss: 1.6099 - val_accuracy: 0.2222\n",
      "Epoch 2/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.5639 - accuracy: 0.3125\n",
      "Epoch 00002: val_loss did not improve from 1.60994\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.5604 - accuracy: 0.3238 - val_loss: 1.6540 - val_accuracy: 0.1852\n",
      "Epoch 3/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.4770 - accuracy: 0.3750\n",
      "Epoch 00003: val_loss improved from 1.60994 to 1.50972, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 1.4835 - accuracy: 0.3714 - val_loss: 1.5097 - val_accuracy: 0.4074\n",
      "Epoch 4/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.3520 - accuracy: 0.6250\n",
      "Epoch 00004: val_loss improved from 1.50972 to 1.39237, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.3627 - accuracy: 0.6000 - val_loss: 1.3924 - val_accuracy: 0.5926\n",
      "Epoch 5/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.2407 - accuracy: 0.7188\n",
      "Epoch 00005: val_loss did not improve from 1.39237\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.2457 - accuracy: 0.7143 - val_loss: 1.4564 - val_accuracy: 0.4074\n",
      "Epoch 6/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.2299 - accuracy: 0.6719\n",
      "Epoch 00006: val_loss improved from 1.39237 to 1.29553, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.2170 - accuracy: 0.7048 - val_loss: 1.2955 - val_accuracy: 0.5556\n",
      "Epoch 7/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.0828 - accuracy: 0.8750\n",
      "Epoch 00007: val_loss improved from 1.29553 to 1.26797, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.0748 - accuracy: 0.8857 - val_loss: 1.2680 - val_accuracy: 0.6296\n",
      "Epoch 8/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.0717 - accuracy: 0.8594\n",
      "Epoch 00008: val_loss improved from 1.26797 to 1.20563, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.0437 - accuracy: 0.8762 - val_loss: 1.2056 - val_accuracy: 0.6667\n",
      "Epoch 9/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9785 - accuracy: 0.9531\n",
      "Epoch 00009: val_loss improved from 1.20563 to 1.19117, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9781 - accuracy: 0.9619 - val_loss: 1.1912 - val_accuracy: 0.7037\n",
      "Epoch 10/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9495 - accuracy: 0.9531\n",
      "Epoch 00010: val_loss improved from 1.19117 to 1.18732, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9347 - accuracy: 0.9714 - val_loss: 1.1873 - val_accuracy: 0.7037\n",
      "Epoch 11/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9542 - accuracy: 0.9531\n",
      "Epoch 00011: val_loss improved from 1.18732 to 1.17648, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9419 - accuracy: 0.9619 - val_loss: 1.1765 - val_accuracy: 0.7407\n",
      "Epoch 12/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9232 - accuracy: 0.9844\n",
      "Epoch 00012: val_loss did not improve from 1.17648\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9262 - accuracy: 0.9810 - val_loss: 1.2238 - val_accuracy: 0.7037\n",
      "Epoch 13/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9323 - accuracy: 0.9688\n",
      "Epoch 00013: val_loss did not improve from 1.17648\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9224 - accuracy: 0.9810 - val_loss: 1.2125 - val_accuracy: 0.7037\n",
      "Epoch 14/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9230 - accuracy: 0.9844\n",
      "Epoch 00014: val_loss did not improve from 1.17648\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9280 - accuracy: 0.9810 - val_loss: 1.2283 - val_accuracy: 0.6667\n",
      "Epoch 15/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9335 - accuracy: 0.9688\n",
      "Epoch 00015: val_loss did not improve from 1.17648\n",
      "105/105 [==============================] - 0s 5ms/sample - loss: 0.9322 - accuracy: 0.9714 - val_loss: 1.2265 - val_accuracy: 0.6667\n",
      "Epoch 16/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9223 - accuracy: 0.9844\n",
      "Epoch 00016: val_loss improved from 1.17648 to 1.13681, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 5ms/sample - loss: 0.9308 - accuracy: 0.9714 - val_loss: 1.1368 - val_accuracy: 0.7778\n",
      "Epoch 17/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9093 - accuracy: 1.0000\n",
      "Epoch 00017: val_loss improved from 1.13681 to 1.04589, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 0.9267 - accuracy: 0.9810 - val_loss: 1.0459 - val_accuracy: 0.8519\n",
      "Epoch 18/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9181 - accuracy: 1.0000\n",
      "Epoch 00018: val_loss improved from 1.04589 to 0.98652, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 0.9149 - accuracy: 1.0000 - val_loss: 0.9865 - val_accuracy: 0.9259\n",
      "Epoch 19/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9075 - accuracy: 1.0000\n",
      "Epoch 00019: val_loss improved from 0.98652 to 0.97183, saving model to best_model_LSTM.h5\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 0.9072 - accuracy: 1.0000 - val_loss: 0.9718 - val_accuracy: 0.9259\n",
      "Epoch 20/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9073 - accuracy: 1.0000\n",
      "Epoch 00020: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 0.9068 - accuracy: 1.0000 - val_loss: 1.0012 - val_accuracy: 0.9259\n",
      "Epoch 21/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9053 - accuracy: 1.0000\n",
      "Epoch 00021: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9052 - accuracy: 1.0000 - val_loss: 1.0443 - val_accuracy: 0.8519\n",
      "Epoch 22/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9052 - accuracy: 1.0000\n",
      "Epoch 00022: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9051 - accuracy: 1.0000 - val_loss: 1.0533 - val_accuracy: 0.8519\n",
      "Epoch 23/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9053 - accuracy: 1.0000\n",
      "Epoch 00023: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9052 - accuracy: 1.0000 - val_loss: 1.0608 - val_accuracy: 0.8519\n",
      "Epoch 24/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9151 - accuracy: 1.0000\n",
      "Epoch 00024: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 0.9112 - accuracy: 1.0000 - val_loss: 1.1300 - val_accuracy: 0.7778\n",
      "Epoch 25/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9052 - accuracy: 1.0000\n",
      "Epoch 00025: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 0.9159 - accuracy: 0.9905 - val_loss: 1.1394 - val_accuracy: 0.7407\n",
      "Epoch 26/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9064 - accuracy: 1.0000\n",
      "Epoch 00026: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9059 - accuracy: 1.0000 - val_loss: 1.0687 - val_accuracy: 0.8519\n",
      "Epoch 27/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9051 - accuracy: 1.0000\n",
      "Epoch 00027: val_loss did not improve from 0.97183\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9147 - accuracy: 0.9905 - val_loss: 1.0571 - val_accuracy: 0.8519\n",
      "Epoch 28/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9066 - accuracy: 1.0000\n",
      "Epoch 00028: val_loss did not improve from 0.97183\n",
      "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9061 - accuracy: 1.0000 - val_loss: 1.1104 - val_accuracy: 0.7778\n"
     ]
    }
   ],
   "source": [
    "# ËÆ≠ÁªÉLSTMÊ®°Âûã\n",
    "hist_LSTM = model_LSTM.fit(train_embed, # ËÆ≠ÁªÉÊï∞ÊçÆËØçÂêëÈáèÁâπÂæÅ\n",
    "                           train_y_one_hot, # ËÆ≠ÁªÉÊï∞ÊçÆone-hotÁºñÁ†Å\n",
    "                           epochs=epochs, # Ëø≠‰ª£Ê¨°Êï∞\n",
    "                           batch_size=64, # ÊâπÈáè\n",
    "                           shuffle=True, # ÊòØÂê¶ÈöèÊú∫Êâì‰π±\n",
    "                           validation_split=0.2, # È™åËØÅÈõÜÂàíÂàÜÊØî‰æã\n",
    "                           callbacks=[early_stop, checkpoint_LSTM] # Âä†ÂÖ•early_stopÂíåcheckpoint\n",
    "                          )\n",
    "model_LSTM.save_weights('/Users/xujie/Desktop/Python/nlp/È°πÁõÆ/Ë°®ÊÉÖÁ¨¶Âè∑È¢ÑÊµã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 105 samples, validate on 27 samples\n",
      "Epoch 1/60\n",
      " 64/105 [=================>............] - ETA: 7s - loss: 1.6060 - accuracy: 0.2812\n",
      "Epoch 00001: val_loss improved from inf to 1.61720, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 13s 128ms/sample - loss: 1.5965 - accuracy: 0.2952 - val_loss: 1.6172 - val_accuracy: 0.2222\n",
      "Epoch 2/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.5020 - accuracy: 0.3594\n",
      "Epoch 00002: val_loss did not improve from 1.61720\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.5418 - accuracy: 0.2857 - val_loss: 1.6451 - val_accuracy: 0.1852\n",
      "Epoch 3/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.5702 - accuracy: 0.2656\n",
      "Epoch 00003: val_loss improved from 1.61720 to 1.51836, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 1.5465 - accuracy: 0.3143 - val_loss: 1.5184 - val_accuracy: 0.3333\n",
      "Epoch 4/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.4447 - accuracy: 0.4531\n",
      "Epoch 00004: val_loss improved from 1.51836 to 1.38592, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 1s 6ms/sample - loss: 1.4292 - accuracy: 0.5238 - val_loss: 1.3859 - val_accuracy: 0.5556\n",
      "Epoch 5/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.2958 - accuracy: 0.7031\n",
      "Epoch 00005: val_loss improved from 1.38592 to 1.28291, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 1s 5ms/sample - loss: 1.2660 - accuracy: 0.7238 - val_loss: 1.2829 - val_accuracy: 0.6667\n",
      "Epoch 6/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.1795 - accuracy: 0.7188\n",
      "Epoch 00006: val_loss improved from 1.28291 to 1.21995, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 1s 6ms/sample - loss: 1.1719 - accuracy: 0.7524 - val_loss: 1.2200 - val_accuracy: 0.7778\n",
      "Epoch 7/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.0608 - accuracy: 0.8281\n",
      "Epoch 00007: val_loss improved from 1.21995 to 1.15915, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 0s 5ms/sample - loss: 1.0694 - accuracy: 0.8381 - val_loss: 1.1591 - val_accuracy: 0.8148\n",
      "Epoch 8/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.0278 - accuracy: 0.9062\n",
      "Epoch 00008: val_loss did not improve from 1.15915\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9967 - accuracy: 0.9333 - val_loss: 1.1711 - val_accuracy: 0.7778\n",
      "Epoch 9/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 1.0274 - accuracy: 0.8906\n",
      "Epoch 00009: val_loss improved from 1.15915 to 1.14291, saving model to best_model_GRU.h5\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9935 - accuracy: 0.9238 - val_loss: 1.1429 - val_accuracy: 0.7778\n",
      "Epoch 10/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9382 - accuracy: 0.9688\n",
      "Epoch 00010: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9512 - accuracy: 0.9524 - val_loss: 1.1959 - val_accuracy: 0.7037\n",
      "Epoch 11/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9834 - accuracy: 0.9062\n",
      "Epoch 00011: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 2ms/sample - loss: 0.9620 - accuracy: 0.9333 - val_loss: 1.1553 - val_accuracy: 0.7407\n",
      "Epoch 12/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9396 - accuracy: 0.9688\n",
      "Epoch 00012: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9620 - accuracy: 0.9429 - val_loss: 1.1617 - val_accuracy: 0.7407\n",
      "Epoch 13/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9788 - accuracy: 0.9219\n",
      "Epoch 00013: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9767 - accuracy: 0.9333 - val_loss: 1.1494 - val_accuracy: 0.7778\n",
      "Epoch 14/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9374 - accuracy: 0.9688\n",
      "Epoch 00014: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9340 - accuracy: 0.9714 - val_loss: 1.1731 - val_accuracy: 0.7407\n",
      "Epoch 15/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9215 - accuracy: 0.9844\n",
      "Epoch 00015: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9343 - accuracy: 0.9714 - val_loss: 1.1562 - val_accuracy: 0.7407\n",
      "Epoch 16/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9374 - accuracy: 0.9688\n",
      "Epoch 00016: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 3ms/sample - loss: 0.9250 - accuracy: 0.9810 - val_loss: 1.1714 - val_accuracy: 0.7037\n",
      "Epoch 17/60\n",
      " 64/105 [=================>............] - ETA: 0s - loss: 0.9364 - accuracy: 0.9688\n",
      "Epoch 00017: val_loss did not improve from 1.14291\n",
      "105/105 [==============================] - 0s 4ms/sample - loss: 0.9258 - accuracy: 0.9810 - val_loss: 1.1623 - val_accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "# ËÆ≠ÁªÉGRUÊ∑±Â∫¶Á•ûÁªèÁΩëÁªú\n",
    "hist_GRU = model_GRU.fit(train_embed, # ËÆ≠ÁªÉÊï∞ÊçÆËØçÂêëÈáèÁâπÂæÅ\n",
    "                         train_y_one_hot, # ËÆ≠ÁªÉÊï∞ÊçÆone-hotÁºñÁ†Å\n",
    "                         epochs=epochs, # Ëø≠‰ª£Ê¨°Êï∞\n",
    "                         batch_size=64, # ÊâπÈáè\n",
    "                         shuffle=True, # ÊòØÂê¶ÈöèÊú∫Êâì‰π±\n",
    "                         validation_split=0.2, # È™åËØÅÈõÜÂàíÂàÜÊØî‰æã\n",
    "                         callbacks=[early_stop, checkpoint_GRU] # Âä†ÂÖ•early_stopÂíåcheckpoint\n",
    "                        )\n",
    "model_GRU.save_weights('/Users/xujie/Desktop/Python/nlp/È°πÁõÆ/Ë°®ÊÉÖÁ¨¶Âè∑È¢ÑÊµã')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "# ÂÆö‰πâÂØπÈ¢ÑÊµãÁªìÊûúËøõË°åËØÑ‰º∞ÁöÑÂáΩÊï∞report_results() \n",
    "\n",
    "# ËØÑ‰º∞ÂÜÖÂÆπÂåÖÊã¨: precision recall F1-score\n",
    "def report_results(test_y, pred, method=''):\n",
    "    # ËÆ°ÁÆóÊ∑∑Ê∑ÜÁü©Èòµ\n",
    "    confm = confusion_matrix(test_y, pred)\n",
    "    # ÂØπÊ∑∑Ê∑ÜÁü©ÈòµËøõË°åÂèØËßÜÂåñ\n",
    "    plt.figure(figsize=(8,8))\n",
    "    sns.heatmap(confm.T, square=True, annot=True, fmt='d', cbar=False)\n",
    "    plt.xlabel('True Label')\n",
    "    plt.ylabel('Predicr Label')\n",
    "    plt.title(method+' '+'Confusion Matrix')\n",
    "    plt.show()\n",
    "    # printÂàÜÁ±ªprecision recall Âíå F-1 ScoreÁöÑÊä•Âëä\n",
    "    print(method+' '+'Classification ReportÔºö', '\\n', classification_report(test_y, pred))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTM Classification ReportÔºö \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.50        12\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.70      0.89      0.78        18\n",
      "           3       0.68      0.87      0.76        15\n",
      "           4       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.75        56\n",
      "   macro avg       0.84      0.74      0.75        56\n",
      "weighted avg       0.80      0.75      0.73        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Âú®ÊµãËØïÈõÜ‰∏äÂØπLSTMÊ®°ÂûãËøõË°åÈ¢ÑÊµã\n",
    "pred_LSTM = model_LSTM.predict_classes(test_embed)\n",
    "\n",
    "# ËØÑ‰º∞Ê®°Âûã\n",
    "report_results(test_y, pred_LSTM, method='LSTM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRU Classification ReportÔºö \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.33      0.42        12\n",
      "           1       1.00      0.80      0.89         5\n",
      "           2       0.85      0.61      0.71        18\n",
      "           3       0.52      0.80      0.63        15\n",
      "           4       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.66        56\n",
      "   macro avg       0.72      0.71      0.69        56\n",
      "weighted avg       0.69      0.66      0.65        56\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Âú®ÊµãËØïÈõÜ‰∏äÂØπGRUÊ®°ÂûãËøõË°åÈ¢ÑÊµã\n",
    "pred_GRU = model_GRU.predict_classes(test_embed)\n",
    "\n",
    "# ËØÑ‰º∞Ê®°Âûã\n",
    "report_results(test_y, pred_GRU, method='GRU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: I want to eat\t predict_LSTM: üç¥ predict_GRU: üç¥ true: üç¥\n",
      "text: he did not answer\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: he got a raise\t predict_LSTM: üòÉ predict_GRU: üòì true: üòÉ\n",
      "text: she got me a present\t predict_LSTM: üòÉ predict_GRU: üòì true: üß°\n",
      "text: ha ha ha it was so funny\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: he is a good friend\t predict_LSTM: üòÉ predict_GRU: üß° true: üß°\n",
      "text: I am upset\t predict_LSTM: üòì predict_GRU: üòì true: üß°\n",
      "text: We had such a lovely dinner tonight\t predict_LSTM: üòÉ predict_GRU: üç¥ true: üß°\n",
      "text: where is the food\t predict_LSTM: üç¥ predict_GRU: üç¥ true: üç¥\n",
      "text: Stop making this joke ha ha ha\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: where is the ball\t predict_LSTM: ‚öæ predict_GRU: ‚öæ true: ‚öæ\n",
      "text: work is hard\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: This girl is messing with me\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: are you serious ha ha\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: Let us go play baseball\t predict_LSTM: ‚öæ predict_GRU: ‚öæ true: ‚öæ\n",
      "text: This stupid grader is not working \t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: work is horrible\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: Congratulation for having a baby\t predict_LSTM: üòÉ predict_GRU: üß° true: üòÉ\n",
      "text: stop messing around\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: any suggestions for dinner\t predict_LSTM: üç¥ predict_GRU: üç¥ true: üç¥\n",
      "text: I love taking breaks\t predict_LSTM: üòì predict_GRU: üß° true: üß°\n",
      "text: you brighten my day\t predict_LSTM: üòì predict_GRU: üòì true: üòÉ\n",
      "text: I boiled rice\t predict_LSTM: üç¥ predict_GRU: üç¥ true: üç¥\n",
      "text: she is a bully\t predict_LSTM: üòì predict_GRU: üß° true: üòì\n",
      "text: Why are you feeling bad\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: I am upset\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: I worked during my birthday\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòì\n",
      "text: My grandmother is the love of my life\t predict_LSTM: üß° predict_GRU: üòì true: üß°\n",
      "text: enjoy your break\t predict_LSTM: üòÉ predict_GRU: üç¥ true: üòÉ\n",
      "text: valentine day is near\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üß°\n",
      "text: I miss you so much\t predict_LSTM: üß° predict_GRU: üß° true: üß°\n",
      "text: throw the ball\t predict_LSTM: ‚öæ predict_GRU: ‚öæ true: ‚öæ\n",
      "text: My life is so boring\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: she said yes\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: will you be my valentine\t predict_LSTM: üòì predict_GRU: üòì true: üß°\n",
      "text: he can pitch really well\t predict_LSTM: üòÉ predict_GRU: üòì true: ‚öæ\n",
      "text: dance with me\t predict_LSTM: üòÉ predict_GRU: üòì true: üòÉ\n",
      "text: I am starving\t predict_LSTM: üòì predict_GRU: üç¥ true: üç¥\n",
      "text: See you at the restaurant\t predict_LSTM: üç¥ predict_GRU: üç¥ true: üç¥\n",
      "text: I like to laugh\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: I will go dance predict_LSTM: üòÉ predict_GRU: üòì true: üòÉ\n",
      "text: I like your jacket \t predict_LSTM: üòì predict_GRU: üß° true: üòÉ\n",
      "text: i miss her\t predict_LSTM: üß° predict_GRU: üß° true: üß°\n",
      "text: what is your favorite baseball game\t predict_LSTM: ‚öæ predict_GRU: ‚öæ true: ‚öæ\n",
      "text: Good job\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: I love to the stars and back\t predict_LSTM: üß° predict_GRU: üòì true: üß°\n",
      "text: What you did was awesome\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: ha ha ha lol\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: I want to joke\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: go away\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: yesterday we lost again\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: family is all I have\t predict_LSTM: üòÉ predict_GRU: üòì true: üß°\n",
      "text: you are failing this exercise\t predict_LSTM: üòì predict_GRU: üòì true: üòì\n",
      "text: Good joke\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: You totally deserve this prize\t predict_LSTM: üòÉ predict_GRU: üòÉ true: üòÉ\n",
      "text: I did not have breakfast  predict_LSTM: üç¥ predict_GRU: üç¥ true: üòì\n"
     ]
    }
   ],
   "source": [
    "# ËæìÂá∫LSTMÂíåGRUÊ∑±Â∫¶Á•ûÁªèÁΩëÁªúÈ¢ÑÊµãÁöÑÁªìÊûú\n",
    "for i in range(test_X.shape[0]):\n",
    "    print('text:', test_X[i],  \n",
    "          'predict_LSTM:', emoji.emojize(emoji_dic[pred_LSTM[i]]),\n",
    "          'predict_GRU:', emoji.emojize(emoji_dic[pred_GRU[i]]), \n",
    "          'true:', emoji.emojize(emoji_dic[test_y[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
